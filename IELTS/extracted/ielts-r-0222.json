{
  "id": "ielts-r-0222",
  "slug": "information-theory---the-big-idea",
  "title": "Information theory - the big idea",
  "page_range": [
    1123,
    1127
  ],
  "passage_text": "Reading Practice\n \nInformation theory - the big idea\nInformation theory lies at the heart of everything - from DVD players and the genetic code\nof DNA to the physics of the universe at its most fundamental. It has been central to the\ndevelopment of the science of communication, which enables data to be sent electronically\nand has therefore had a major impact on our lives\nA\nIn April 2002 an event took place which demonstrated one of the many applications of\ninformation theory. The space probe, Voyager I, launched in 1977, had sent\nback spectacular images of Jupiter and Saturn and then soared out of the Solar System on\na one-way mission to the stars. After 25 years of exposure to the freezing temperatures of\ndeep space, the probe was beginning to show its age. Sensors and circuits were on the\nbrink of failing and NASA experts realised that they had to do something or lose contact\nwith their probe forever. The solution was to get a message to Voyager I to instruct it to use\nspares to change the failing parts. With the probe 12 billion kilometres from Earth, this was\nnot an easy task. By means of a radio dish belonging to NASA’s Deep Space Network, the\nmessage was sent out into the depths of space. Even travelling at the speed of light, it took\nover 11 hours to reach its target, far beyond the orbit of Pluto. Yet, incredibly, the little\nprobe managed to hear the faint call from its home planet, and successfully made the\nswitchover.\nB\nIt was the longest-distance repair job in history, and a triumph for the NASA engineers. But\nit also highlighted the astonishing power of the techniques developed by American\ncommunications engineer Claude Shannon, who had died just a year earlier. Born in 1916\nin Petoskey, Michigan, Shannon showed an early talent for maths and for building gadgets,\nand made breakthroughs in the foundations of computer technology when still a student.\nWhile at Bell Laboratories, Shannon developed information theory, but shunned the\nresulting acclaim. In the 1940s, he single-handedly created an entire science of\ncommunication which has since inveigled its way into a host of applications, from DVDs to\nsatellite communications to bar codes - any area, in short, where data has to be conveyed\nrapidly yet accurately.\nC\nThis all seems light years away from the down-to-earth uses Shannon originally had for his\nwork, which began when he was a 22-year-old graduate engineering student at the\nprestigious Massachusetts Institute of Technology in 1939. He set out with an apparently\nsimple aim: to pin down the precise meaning of the concept of ‘information’. The most basic\nform of information, Shannon argued, is whether something is true or false - which can be\ncaptured in the binary unit, or ‘bit’, of the form 1 or 0. Having identified this fundamental\nunit, Shannon set about defining otherwise vague ideas about information and how to\ntransmit it from place to place. In the process he discovered something surprising: it is\nalways possible to guarantee information will get through random interference - ‘noise’ -\nintact.\nD\n \n1\n\nNoise usually means unwanted sounds which interfere with genuine information.\nInformation theory generalises this idea via theorems that capture the effects of noise with\nmathematical precision. In particular, Shannon showed that noise sets a limit on the rate at\nwhich information can pass along communication channels while remaining error-free. This\nrate depends on the relative strengths of the signal and noise travelling down the\ncommunication channel, and on its capacity (its ‘bandwidth’). The resulting limit, given in\nunits of bits per second, is the absolute maximum rate of error-free communication given\nsignal strength and noise level. The trick, Shannon showed, is to find ways of packaging up\n- ‘coding’ - information to cope with the ravages of noise, while staying within the\ninformation-carrying capacity - ‘bandwidth’ - of the communication system being used.\nE\nOver the years scientists have devised many such coding methods, and they have proved\ncrucial in many technological feats. The Voyager spacecraft transmitted data using codes\nwhich added one extra bit for every single bit of information; the result was an error rate of\njust one bit in 10,000 - and stunningly clear pictures of the planets. Other codes have\nbecome part of everyday life - such as the Universal Product Code, or bar code, which\nuses a simple error-detecting system that ensures supermarket check-out lasers can read\nthe price even on, say, a crumpled bag of crisps. As recently as 1993, engineers made a\nmajor breakthrough by discovering so-called turbo codes - which come very close to\nShannon’s ultimate limit for the maximum rate that data can be transmitted reliably, and\nnow play a key role in the mobile videophone revolution.\nF\nShannon also laid the foundations of more efficient ways of storing information, by stripping\nout superfluous (‘redundant’) bits from data which contributed little real information. As\nmobile phone text messages like ‘I CN C U’ show, it is often possible to leave out a lot of\ndata without losing much meaning. As with error correction, however, there’s a limit beyond\nwhich messages become too ambiguous. Shannon showed how to calculate this limit,\nopening the way to the design of compression methods that cram maximum information\ninto the minimum space.\n \n2",
  "questions_text": "Questions 1-6\nReading Passage has six paragraphs, A-F.\nWhich paragraph contains the following information?\nWrite the correct letter, A-F, in boxes 1-6 on your answer sheet.\n \n \n \n1.....................    an explanation of the factors affecting the transmission of information\n2.....................    an example of how unnecessary information can be omitted\n3.....................    a reference to Shannon’s attitude to fame\n4.....................    details of a machine capable of interpreting incomplete information\n5.....................    a detailed account of an incident involving information theory\n6.....................    a reference to what Shannon initially intended to achieve in his research\nQuestions 7-11\nComplete the notes below.\nChoose NO MORE THAN THREE WORDS from the passage for each answer.\nWrite your answers in boxes 7-11 on your answer sheet.\n \n \nThe Voyager 1 Space Probe\n•   The probe transmitted pictures of both 7....................., then left the 8.....................\n \n•   The freezing temperatures were found to have a negative effect on parts of the space\nprobe.\n \n•   Scientists feared that both the 9..................... were about to stop working.\n \n•   The only hope was to tell the probe to replace them with 10..................... - but\ndistance made communication with the probe difficult.\n•   A 11..................... was used to transmit the message at the speed of light.\n \n•   The message was picked up by the probe and the switchover took place.\nQuestions 12-14\nDo the following statements agree with the information given in Reading Passage?\n \n3\n\n \n \nIn boxes 12-14 on your answer sheet, write\n \nTRUE    if the statement agrees with the information\nFALSE    if the statement contradicts the information\nNOT GIVEN if there is no information on this\n12.....................    The concept of describing something as true or false was the starting\npoint for Shannon in his attempts to send messages over distances.\n13.....................    The amount of information that can be sent in a given time period is\ndetermined with reference to the signal strength and noise level.\n14.....................    Products have now been developed which can convey more information\nthan Shannon had anticipated as possible.\n \n4",
  "full_text": "Reading Practice\n \nInformation theory - the big idea\nInformation theory lies at the heart of everything - from DVD players and the genetic code\nof DNA to the physics of the universe at its most fundamental. It has been central to the\ndevelopment of the science of communication, which enables data to be sent electronically\nand has therefore had a major impact on our lives\nA\nIn April 2002 an event took place which demonstrated one of the many applications of\ninformation theory. The space probe, Voyager I, launched in 1977, had sent\nback spectacular images of Jupiter and Saturn and then soared out of the Solar System on\na one-way mission to the stars. After 25 years of exposure to the freezing temperatures of\ndeep space, the probe was beginning to show its age. Sensors and circuits were on the\nbrink of failing and NASA experts realised that they had to do something or lose contact\nwith their probe forever. The solution was to get a message to Voyager I to instruct it to use\nspares to change the failing parts. With the probe 12 billion kilometres from Earth, this was\nnot an easy task. By means of a radio dish belonging to NASA’s Deep Space Network, the\nmessage was sent out into the depths of space. Even travelling at the speed of light, it took\nover 11 hours to reach its target, far beyond the orbit of Pluto. Yet, incredibly, the little\nprobe managed to hear the faint call from its home planet, and successfully made the\nswitchover.\nB\nIt was the longest-distance repair job in history, and a triumph for the NASA engineers. But\nit also highlighted the astonishing power of the techniques developed by American\ncommunications engineer Claude Shannon, who had died just a year earlier. Born in 1916\nin Petoskey, Michigan, Shannon showed an early talent for maths and for building gadgets,\nand made breakthroughs in the foundations of computer technology when still a student.\nWhile at Bell Laboratories, Shannon developed information theory, but shunned the\nresulting acclaim. In the 1940s, he single-handedly created an entire science of\ncommunication which has since inveigled its way into a host of applications, from DVDs to\nsatellite communications to bar codes - any area, in short, where data has to be conveyed\nrapidly yet accurately.\nC\nThis all seems light years away from the down-to-earth uses Shannon originally had for his\nwork, which began when he was a 22-year-old graduate engineering student at the\nprestigious Massachusetts Institute of Technology in 1939. He set out with an apparently\nsimple aim: to pin down the precise meaning of the concept of ‘information’. The most basic\nform of information, Shannon argued, is whether something is true or false - which can be\ncaptured in the binary unit, or ‘bit’, of the form 1 or 0. Having identified this fundamental\nunit, Shannon set about defining otherwise vague ideas about information and how to\ntransmit it from place to place. In the process he discovered something surprising: it is\nalways possible to guarantee information will get through random interference - ‘noise’ -\nintact.\nD\n \n1\n\nNoise usually means unwanted sounds which interfere with genuine information.\nInformation theory generalises this idea via theorems that capture the effects of noise with\nmathematical precision. In particular, Shannon showed that noise sets a limit on the rate at\nwhich information can pass along communication channels while remaining error-free. This\nrate depends on the relative strengths of the signal and noise travelling down the\ncommunication channel, and on its capacity (its ‘bandwidth’). The resulting limit, given in\nunits of bits per second, is the absolute maximum rate of error-free communication given\nsignal strength and noise level. The trick, Shannon showed, is to find ways of packaging up\n- ‘coding’ - information to cope with the ravages of noise, while staying within the\ninformation-carrying capacity - ‘bandwidth’ - of the communication system being used.\nE\nOver the years scientists have devised many such coding methods, and they have proved\ncrucial in many technological feats. The Voyager spacecraft transmitted data using codes\nwhich added one extra bit for every single bit of information; the result was an error rate of\njust one bit in 10,000 - and stunningly clear pictures of the planets. Other codes have\nbecome part of everyday life - such as the Universal Product Code, or bar code, which\nuses a simple error-detecting system that ensures supermarket check-out lasers can read\nthe price even on, say, a crumpled bag of crisps. As recently as 1993, engineers made a\nmajor breakthrough by discovering so-called turbo codes - which come very close to\nShannon’s ultimate limit for the maximum rate that data can be transmitted reliably, and\nnow play a key role in the mobile videophone revolution.\nF\nShannon also laid the foundations of more efficient ways of storing information, by stripping\nout superfluous (‘redundant’) bits from data which contributed little real information. As\nmobile phone text messages like ‘I CN C U’ show, it is often possible to leave out a lot of\ndata without losing much meaning. As with error correction, however, there’s a limit beyond\nwhich messages become too ambiguous. Shannon showed how to calculate this limit,\nopening the way to the design of compression methods that cram maximum information\ninto the minimum space.\n \n2\n\nQuestions 1-6\nReading Passage has six paragraphs, A-F.\nWhich paragraph contains the following information?\nWrite the correct letter, A-F, in boxes 1-6 on your answer sheet.\n \n \n \n1.....................    an explanation of the factors affecting the transmission of information\n2.....................    an example of how unnecessary information can be omitted\n3.....................    a reference to Shannon’s attitude to fame\n4.....................    details of a machine capable of interpreting incomplete information\n5.....................    a detailed account of an incident involving information theory\n6.....................    a reference to what Shannon initially intended to achieve in his research\nQuestions 7-11\nComplete the notes below.\nChoose NO MORE THAN THREE WORDS from the passage for each answer.\nWrite your answers in boxes 7-11 on your answer sheet.\n \n \nThe Voyager 1 Space Probe\n•   The probe transmitted pictures of both 7....................., then left the 8.....................\n \n•   The freezing temperatures were found to have a negative effect on parts of the space\nprobe.\n \n•   Scientists feared that both the 9..................... were about to stop working.\n \n•   The only hope was to tell the probe to replace them with 10..................... - but\ndistance made communication with the probe difficult.\n•   A 11..................... was used to transmit the message at the speed of light.\n \n•   The message was picked up by the probe and the switchover took place.\nQuestions 12-14\nDo the following statements agree with the information given in Reading Passage?\n \n3\n\n \n \nIn boxes 12-14 on your answer sheet, write\n \nTRUE    if the statement agrees with the information\nFALSE    if the statement contradicts the information\nNOT GIVEN if there is no information on this\n12.....................    The concept of describing something as true or false was the starting\npoint for Shannon in his attempts to send messages over distances.\n13.....................    The amount of information that can be sent in a given time period is\ndetermined with reference to the signal strength and noise level.\n14.....................    Products have now been developed which can convey more information\nthan Shannon had anticipated as possible.\n \n4",
  "solution_text": "Solution:\n\n 1. D                    8. Solar System\n\n                         9. sensors and\n                           circuits IN EITHER\n 2. F             ORDER; BOTH\n                REQUIRED FOR\n              ONE MARK\n\n 3. B                  10. spares\n\n 4. E                  11. radio dish\n\n 5. A                  12. TRUE\n\n 6. C                  13. TRUE\n\n 7. Jupiter and\n Saturn IN EITHER\n ORDER; BOTH       14. FALSE\n REQUIRED FOR\n ONE MARK\n\n\n\n\n\n                                                                  5",
  "answer_key": {
    "1": "D",
    "8": "Solar System",
    "9": "sensors and circuits IN EITHER",
    "2": "F ORDER; BOTH REQUIRED FOR ONE MARK",
    "3": "B",
    "10": "spares",
    "4": "E",
    "11": "radio dish",
    "5": "A",
    "12": "TRUE",
    "6": "C",
    "13": "TRUE",
    "7": "Jupiter and Saturn IN EITHER ORDER; BOTH",
    "14": "FALSE REQUIRED FOR ONE MARK"
  },
  "question_sections": [
    {
      "label": "Questions 1-6",
      "page": 1125
    },
    {
      "label": "Questions 7-11",
      "page": 1125
    },
    {
      "label": "Questions 12-14",
      "page": 1125
    }
  ],
  "extracted_at": "2026-02-25T17:37:00.592034"
}
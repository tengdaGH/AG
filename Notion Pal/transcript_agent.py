#!/usr/bin/env python3
"""
Autonomous Notion Transcript Agent

Polls æ•™å­¦é€å­—ç¨¿è®°å½• for entries with æ¸…æ´—çŠ¶æ€ = å¾…æ¸…æ´—,
reads the raw transcript, and executes the 5-phase processing pipeline.

The AI analysis step (transcript â†’ structured notes) is designed to be
performed by Antigravity's internal compute. This script handles the
Notion CRUD orchestration.

Usage:
  # Single-shot: process all pending entries once
  python transcript_agent.py --once

  # Polling mode: check every 30 seconds
  python transcript_agent.py

  # Process a specific entry by page ID
  python transcript_agent.py --page-id <PAGE_ID>

  # Create test data for verification
  python transcript_agent.py --create-test
"""

import argparse
import json
import sys
import time
import traceback
from datetime import datetime

import notion_api as notion
from config import (
    TRIGGER_DB, SCHEDULE_DB, QUALITY_DB, TRACKING_DB,
    STATUS_PENDING, STATUS_PROCESSING, STATUS_DONE,
    POLL_INTERVAL_SECONDS,
)
from transcript_processor import (
    phase0_find_session,
    phase1_write_notes,
    phase2_backup_transcript,
    phase3_teaching_quality,
    phase4_student_tracking,
    update_trigger_status,
    extract_trigger_metadata,
)


def find_pending_entries() -> list:
    """Query the trigger database for entries with æ¸…æ´—çŠ¶æ€ = å¾…æ¸…æ´—."""
    results = notion.query_database(
        TRIGGER_DB,
        filter={
            "property": "æ¸…æ´—çŠ¶æ€",
            "status": {"equals": STATUS_PENDING}
        }
    )
    print(f"Found {len(results)} pending entries")
    return results


def read_transcript(page_id: str) -> str:
    """Read the raw transcript text from a trigger entry's page body."""
    return notion.get_page_text(page_id)


def process_entry(page: dict, structured_data: dict = None):
    """
    Process a single trigger entry through the 5-phase pipeline.

    If structured_data is provided, skip AI analysis and use it directly.
    If not provided, read transcript and output it for external processing.
    """
    page_id = page["id"]
    meta = extract_trigger_metadata(page)

    print(f"\n{'='*60}")
    print(f"Processing: {meta['title']}")
    print(f"  Student: {meta['student']}")
    print(f"  Subject: {meta['subject']}")
    print(f"  Date: {meta['date']}")
    print(f"  Teacher: {meta['teacher']}")
    print(f"  Exam: {meta['exam']}")
    print(f"{'='*60}")

    # Lock the entry
    update_trigger_status(page_id, STATUS_PROCESSING)

    try:
        # Read raw transcript
        raw_transcript = read_transcript(page_id)
        print(f"\n  Raw transcript length: {len(raw_transcript)} chars")

        if not structured_data:
            # No AI data provided â€” output transcript for external processing
            print("\n" + "="*60)
            print("TRANSCRIPT CONTENT (for AI analysis):")
            print("="*60)
            print(raw_transcript)
            print("="*60)
            print("\nTo complete processing, re-run with --structured-data <json_file>")
            print(f"  Page ID: {page_id}")
            # Keep status as æ¸…æ´—ä¸­ so we can resume
            return {"status": "awaiting_analysis", "page_id": page_id, "meta": meta}

        # Phase 0 + Phase 2 (parallel in concept, sequential in script)
        session_page = None
        if meta["date"]:
            session_page = phase0_find_session(meta["date"])

        if not session_page:
            # Create a new Session page if none found
            print("  [Phase 0] Creating new session page...")
            session_page = notion.create_page(
                parent={"database_id": SCHEDULE_DB},
                properties={
                    "Session": {"title": [{"text": {"content": f"{meta['date']} {meta['subject']}è¯¾"}}]},
                    "Date/Period": {"date": {"start": meta["date"]}} if meta["date"] else {},
                },
            )
            print(f"  [Phase 0] âœ… Created session page: {session_page['id']}")

        session_id = session_page["id"]

        # Phase 1: Write structured notes
        phase1_write_notes(session_id, structured_data)

        # Phase 2: Backup transcript
        phase2_backup_transcript(session_id, raw_transcript)

        # Phase 3 + Phase 4 (parallel in concept)
        phase3_teaching_quality(meta, structured_data)
        phase4_student_tracking(meta, structured_data)

        # Mark as done
        update_trigger_status(page_id, STATUS_DONE)

        # Update summary on trigger entry
        if structured_data.get("highlights"):
            notion.update_page(page_id, {
                "æ‘˜è¦": {"rich_text": [{"text": {"content": structured_data["highlights"][:2000]}}]}
            })

        print(f"\nâœ… All phases complete for: {meta['title']}")
        return {"status": "complete", "page_id": page_id}

    except Exception as e:
        print(f"\nâŒ Error processing {meta['title']}: {e}")
        traceback.print_exc()
        # Revert status on failure
        try:
            update_trigger_status(page_id, STATUS_PENDING)
        except Exception:
            pass
        return {"status": "error", "page_id": page_id, "error": str(e)}


def create_test_data():
    """Create test entries for verification."""
    print("Creating test data...")

    # 1. Create a Session page in å°æ¥·è¯¾è¡¨
    print("\n1. Creating test Session in å°æ¥·è¯¾è¡¨...")
    session = notion.create_page(
        parent={"database_id": SCHEDULE_DB},
        properties={
            "Session": {"title": [{"text": {"content": "2026-02-25 å†™ä½œæ­£è¯¾"}}]},
            "Date/Period": {"date": {"start": "2026-02-25"}},
        },
    )
    print(f"   âœ… Session created: {session['id']}")

    # 2. Create a transcript entry in æ•™å­¦é€å­—ç¨¿è®°å½•
    print("\n2. Creating test transcript entry...")
    test_transcript = _get_test_transcript()

    entry = notion.create_page(
        parent={"database_id": TRIGGER_DB},
        properties={
            "è¯¾ç¨‹åç§°": {"title": [{"text": {"content": "å°æ¥·-å†™ä½œ-2026-02-25-æ­£è¯¾-æ»•è¾¾"}}]},
            "æ—¥æœŸ": {"date": {"start": "2026-02-25"}},
            "å­¦ç”Ÿ": {"multi_select": [{"name": "å°æ¥·"}]},
            "æ•™å¸ˆ": {"multi_select": [{"name": "æ»•è¾¾"}]},
            "ç§‘ç›®": {"select": {"name": "å†™ä½œ"}},
            "è€ƒè¯•ç±»å‹": {"select": {"name": "é›…æ€"}},
            "æ¸…æ´—çŠ¶æ€": {"status": {"name": STATUS_PENDING}},
        },
    )
    print(f"   âœ… Transcript entry created: {entry['id']}")

    # Write transcript content to page body
    notion.append_blocks(entry["id"], [
        {"type": "paragraph", "paragraph": {
            "rich_text": [{"type": "text", "text": {"content": chunk}}]
        }}
        for chunk in [test_transcript[i:i+2000] for i in range(0, len(test_transcript), 2000)]
    ])
    print(f"   âœ… Transcript body written ({len(test_transcript)} chars)")

    print(f"\n{'='*60}")
    print("Test data created successfully!")
    print(f"  Session ID: {session['id']}")
    print(f"  Trigger entry ID: {entry['id']}")
    print(f"{'='*60}")

    return {"session_id": session["id"], "entry_id": entry["id"]}


def _get_test_transcript() -> str:
    """Return a mock teaching transcript for testing."""
    return """æ»•è¾¾ï¼šå¥½ï¼Œå°æ¥·ï¼Œæˆ‘ä»¬ä»Šå¤©æ¥çœ‹é›…æ€å°ä½œæ–‡ï¼ŒæŸ±çŠ¶å›¾ã€‚ä½ å…ˆçœ‹çœ‹è¿™ä¸ªé¢˜ç›®ï¼Œæè¿°ä¸€ä¸‹ä½ çœ‹åˆ°äº†ä»€ä¹ˆã€‚

å°æ¥·ï¼šå—¯...è¿™ä¸ªå›¾è¡¨æ˜¾ç¤ºäº†äº”ä¸ªå›½å®¶åœ¨2015å¹´å’Œ2020å¹´çš„æ—…æ¸¸æ”¶å…¥ã€‚

æ»•è¾¾ï¼šå¯¹ï¼Œé‚£ä½ è§‰å¾—æœ€å¤§çš„ç‰¹ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ

å°æ¥·ï¼šç¾å›½ä¸¤å¹´éƒ½æ˜¯æœ€é«˜çš„ï¼Œç„¶åä¸­å›½å¢é•¿æœ€å¤šã€‚

æ»•è¾¾ï¼šå¾ˆå¥½ï¼ä½ æŠ“ä½äº†æœ€æ ¸å¿ƒçš„è¶‹åŠ¿ã€‚ç°åœ¨æˆ‘ä»¬æ¥æŠŠå®ƒå†™å‡ºæ¥ã€‚å…ˆå†™opening paragraphï¼Œä½ è¯•è¯•çœ‹ã€‚

å°æ¥·ï¼šThe bar chart shows the tourism revenue of five countries in 2015 and 2020.

æ»•è¾¾ï¼šOKï¼Œè¿™ä¸ªå¥å­è¯­æ³•æ²¡é—®é¢˜ï¼Œä½†å¤ªç®€å•äº†ã€‚æˆ‘ä»¬å¯ä»¥ç”¨ illustrates æ›¿æ¢ showsï¼Œç”¨ income generated from tourism æ›¿æ¢ tourism revenueã€‚è€Œä¸”è¦åŠ ä¸Š the given æ¥ä¿®é¥° bar chartã€‚æ¥ï¼Œä½ å†å†™ä¸€éã€‚

å°æ¥·ï¼šThe given bar chart illustrates the income generated from tourism in five countries in 2015 and 2020.

æ»•è¾¾ï¼šå¥½å¤šäº†ï¼ç°åœ¨æ¥å†™overviewã€‚è®°ä½æˆ‘ä»¬ä¹‹å‰è®²çš„â€”â€”overviewä¸€å®šè¦å†™ä¸¤ä¸ªä¸»è¦è¶‹åŠ¿ï¼Œä¸è¦å†™æ•°å­—ã€‚

å°æ¥·ï¼šOverall, the United States had the highest tourism income in both years, while China shows the most significant increase.

æ»•è¾¾ï¼šæ³¨æ„ï¼"shows"è¿™é‡Œè¦ç”¨è¿‡å»å¼ "showed"ï¼Œå› ä¸ºæˆ‘ä»¬æè¿°çš„æ˜¯è¿‡å»çš„æ•°æ®ã€‚è¿˜æœ‰ï¼Œ"the most significant increase"å¯ä»¥å‡çº§ä¸º "witnessed the most remarkable surge"ã€‚

æ»•è¾¾ï¼šğŸ’¡ è®°ä½è¿™ä¸ªæ›¿æ¢ï¼šincrease â†’ surgeï¼Œè¿™æ˜¯ä¸€ä¸ªB2åˆ°C1çš„å‡çº§ï¼Œè€ƒå®˜çœ‹åˆ°ä¼šåŠ åˆ†çš„ã€‚

å°æ¥·ï¼šæ˜ç™½äº†ã€‚

æ»•è¾¾ï¼šå¥½ï¼Œç°åœ¨æ¥å†™body paragraphã€‚è®°ä½åˆ†ç»„åŸåˆ™â€”â€”æŠŠè¶‹åŠ¿ç›¸ä¼¼çš„å›½å®¶æ”¾åœ¨ä¸€èµ·ã€‚ä½ è§‰å¾—æ€ä¹ˆåˆ†ï¼Ÿ

å°æ¥·ï¼šç¾å›½å’Œæ³•å›½ä¸€ç»„ï¼Œå› ä¸ºå®ƒä»¬éƒ½å¾ˆé«˜ï¼Ÿ

æ»•è¾¾ï¼šæ€è·¯æ˜¯å¯¹çš„ï¼Œä½†åˆ†ç»„ä¾æ®åº”è¯¥æ˜¯è¶‹åŠ¿æ–¹å‘ï¼Œä¸åªæ˜¯æ•°å€¼é«˜ä½ã€‚ç¾å›½ã€æ³•å›½å’Œè‹±å›½å¯ä»¥ä¸€ç»„â€”â€”å®ƒä»¬å¢é•¿å¹…åº¦é€‚ä¸­ã€‚ä¸­å›½å’Œæ—¥æœ¬ä¸€ç»„â€”â€”ä¸­å›½å¤§å¹…å¢é•¿ï¼Œæ—¥æœ¬ç•¥æœ‰ä¸‹é™ã€‚è¿™å«"å¯¹æ¯”åˆ†ç»„æ³•"ã€‚

æ»•è¾¾ï¼šğŸ’¡ "æ°¸è¿œè®°ä½ï¼Œåˆ†ç»„ä¸æ˜¯çœ‹è°å¤§è°å°ï¼Œæ˜¯çœ‹è°è·Ÿè°èµ°åŠ¿åƒ"

æ»•è¾¾ï¼šå¥½äº†ï¼Œä»Šå¤©è¯¾åä»»åŠ¡ï¼š
1. æŠŠä»Šå¤©è¿™ç¯‡æŸ±çŠ¶å›¾å°ä½œæ–‡é‡æ–°å†™ä¸€éå®Œæ•´ç‰ˆ
2. æŠŠæ›¿æ¢è¯è¡¨é‡Œçš„è¯é€ ä¸‰ä¸ªå¥å­
3. é¢„ä¹ ä¸‹èŠ‚è¯¾çš„é¥¼å›¾æ¨¡æ¿

æ»•è¾¾ï¼šğŸ’¡ "å†™ä½œè¿™ä¸ªä¸œè¥¿ï¼Œä¸æ˜¯ä½ ä¼šå¤šå°‘è¯ï¼Œè€Œæ˜¯ä½ èƒ½ä¸èƒ½åœ¨20åˆ†é’Ÿå†…æŠŠå¯¹çš„è¯ç”¨åœ¨å¯¹çš„åœ°æ–¹ã€‚é‡ä¸é‡è¦ï¼Œå‡†ç¡®åº¦æ‰é‡è¦ã€‚"

æ»•è¾¾ï¼šğŸ’¡ "ä½ ä»Šå¤©overviewå†™å¾—å¾ˆå¥½ï¼Œè¯´æ˜ä½ å·²ç»å­¦ä¼šæ‰¾ä¸»è¶‹åŠ¿äº†ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„è¿›æ­¥ã€‚"

æ»•è¾¾ï¼šä¸‹è¯¾ï¼Œè¾›è‹¦äº†å°æ¥·ï¼"""


def poll_loop():
    """Main polling loop â€” checks for pending entries every N seconds."""
    print(f"Starting polling loop (interval: {POLL_INTERVAL_SECONDS}s)")
    print("Press Ctrl+C to stop\n")

    while True:
        try:
            entries = find_pending_entries()
            for entry in entries:
                result = process_entry(entry)
                if result["status"] == "awaiting_analysis":
                    print("â¸ï¸  Entry awaiting AI analysis â€” skipping for now")
        except KeyboardInterrupt:
            print("\nPolling stopped.")
            break
        except Exception as e:
            print(f"Error in poll loop: {e}")
            traceback.print_exc()

        time.sleep(POLL_INTERVAL_SECONDS)


def main():
    parser = argparse.ArgumentParser(description="Autonomous Notion Transcript Agent")
    parser.add_argument("--once", action="store_true", help="Process all pending entries once, then exit")
    parser.add_argument("--page-id", type=str, help="Process a specific entry by page ID")
    parser.add_argument("--create-test", action="store_true", help="Create test data for verification")
    parser.add_argument("--structured-data", type=str, help="Path to JSON file with structured analysis data")
    args = parser.parse_args()

    if args.create_test:
        create_test_data()
        return

    structured_data = None
    if args.structured_data:
        with open(args.structured_data, "r") as f:
            structured_data = json.load(f)

    if args.page_id:
        page = notion.get_page(args.page_id)
        result = process_entry(page, structured_data)
        print(f"\nResult: {json.dumps(result, indent=2, ensure_ascii=False)}")
        return

    if args.once:
        entries = find_pending_entries()
        for entry in entries:
            result = process_entry(entry, structured_data)
            print(f"\nResult: {json.dumps(result, indent=2, ensure_ascii=False)}")
        return

    poll_loop()


if __name__ == "__main__":
    main()
